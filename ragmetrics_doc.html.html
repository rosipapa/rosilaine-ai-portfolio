<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="manifest" href="manifest.json">
<meta name="theme-color" content="#6366F1" />
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<link rel="apple-touch-icon" href="icon-192.png">
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>LLM Chat Assistant - Documentation</title>
  <style>
    body {
      margin: 0;
      font-family: 'Segoe UI', sans-serif;
      background-color: #F9FAFB;
      color: #111827;
      display: flex;
      flex-direction: column;
      align-items: center;
      min-height: 100vh;
    }

    header {
      background-color: #6366F1;
      color: white;
      padding: 1rem 2rem; /* reduzido */
      width: 100%;
      text-align: center;
    }

    header h1 {
      margin: 0;
      font-size: 1.5rem; /* menor */
      font-weight: 600;
    }

    .content {
      max-width: 700px; /* um pouco menor */
      background: white;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
      padding: 1.2rem 1.5rem; /* menos padding */
      margin: 1.5rem 1rem;
      min-height: 280px; /* altura reduzida */
      position: relative;
      font-size: 0.9rem; /* fonte menor */
      line-height: 1.4;
      overflow-y: auto;
    }

    .content img {
      max-width: 100%;   /* Para não ultrapassar a largura do container */
      height: auto;      /* Mantém a proporção da imagem */
      max-height: 300px; /* Limita a altura para não ficar muito grande */
      display: block;
      margin: 1rem auto; /* Centraliza e dá espaçamento vertical */
      border-radius: 8px; /* Se quiser manter o estilo */
    }

    h2 {
      color: #6366F1;
      font-size: 1.25rem; /* menor */
      margin-bottom: 0.75rem;
    }

    p, ul {
      line-height: 1.4;
      margin-top: 0.5rem;
      margin-bottom: 0.75rem;
    }

    ul {
      margin-left: 1.2rem;
    }

    .buttons {
      display: flex;
      justify-content: center;
      gap: 1rem;
      margin-top: 1rem;
    }

    button {
      background-color: #6366F1;
      border: none;
      color: white;
      padding: 0.4rem 1rem; /* menos padding */
      border-radius: 8px;
      font-size: 0.9rem; /* fonte menor */
      cursor: pointer;
      transition: background-color 0.3s ease;
      min-width: 70px;
    }

    button:hover:not(:disabled) {
      background-color: #4F46E5;
    }

    button:disabled {
      background-color: #A5B4FC;
      cursor: default;
    }

    footer {
      margin: 1.5rem 0;
      color: #6B7280;
      font-size: 0.85rem;
    }

    img {
      max-width: 100%;
      border-radius: 8px;
      margin-top: 1rem;
      height: auto;
    }
  </style>
</head>
<body>

<header>
  <h1>RAGAS Metrics - Project Documentation</h1>
</header>

<main class="content" id="slide-content">
  <!-- Slide content dynamically injected here -->
</main>

<div class="buttons">
  <button id="btn-home">Home</button>
  <button id="btn-prev">Previous</button>
  <button id="btn-next">Next</button>
</div>

<footer>
  Thanks for reviewing this documentation! — Rosilaine Silva
</footer>

<script>
  const slides = [

{
  title: "What is this Project?",
  content: `
    <p>This project implements a Retrieval-Augmented Generation (RAG) chatbot leveraging vector search with FAISS and large language models (LLMs) via Groq API. It aims to provide accurate, context-aware answers by combining retrieved knowledge with advanced prompting techniques.</p>
    <p>The primary objective of this project is to demonstrate the application of the RAGAS evaluation metrics by comparing the performance of two prompting strategies: a standard prompt and a few-shots prompt. This comparison highlights how prompt design influences the quality and accuracy of generated responses within a RAG framework.</p>

  `
},
{
  title: "What is RAGAS?",
  content: `
    <p>RAGAS is an evaluation framework designed to assess the quality of answers generated by Retrieval-Augmented Generation systems. It focuses on metrics that quantify factual accuracy, relevancy, and grounding of the response with respect to retrieved context.</p>
  `
},
{
  title: "RAGAS Metrics Used",
  content: `
      <ul>
      <li><strong>FactualCorrectness:</strong> Measures the truthfulness of the generated answer by comparing it to the ground truth. Scores range from 0 to 1, where 1 indicates fully factual content and 0 indicates incorrect or misleading information. Uses LLM-based evaluation.</li>
      <li><strong>AnswerRelevancy:</strong> Assesses how well the answer addresses the question, scoring from 0 (irrelevant) to 1 (fully relevant). This metric relies on an LLM to judge the pertinence of the response.</li>
      <li><strong>ContextRelevance:</strong> Evaluates the semantic similarity between the retrieved context and the user query using vector embeddings. Scores range from 0 (no relevance) to 1 (highly relevant).</li>
      <li><strong>ResponseGroundedness:</strong> Checks whether the answer is properly supported by the retrieved context, scoring from 0 (unsupported) to 1 (fully grounded). This evaluation uses an LLM to verify grounding.</li>
      </ul>
  `
},
{
  title: "What is Ground Truth?",
  content: `
    <p>Ground truth refers to the correct or reference answer used to objectively evaluate the quality of generated responses. It serves as the gold standard for calculating metrics and ensuring consistent, reproducible assessment.</p>
<p>In this project, the ground truth answers were generated using the LLM itself, leveraging carefully crafted prompts to produce high-quality reference responses. This approach allows us to create reliable benchmarks even when manually curated answers are not available, enabling scalable and consistent evaluation of the model's output.</p>
  `
},
{
  title: "Cost and Free Tier Limitations",
  content: `
    <p>The Groq API for LLaMA3 enforces token-per-minute limits (typically ~6000 tokens/minute). This restricts the number of queries or evaluation tasks processed simultaneously in the free tier, impacting batch evaluation and requiring careful rate management.</p>
<p>For a real-world project, these limits translate into potential bottlenecks and increased operational costs, as scaling up requires managing token usage efficiently or upgrading to paid plans. Careful cost optimization and monitoring are essential to balance performance needs with budget constraints.</p>

  `
},
{
  title: "Comparison of RAGAS with Other Metrics",
  content: `
    <p>This project compares RAGAS with other popular evaluation frameworks like LLM-as-judge, BERTScore, and ROUGE. The comparison highlights different strengths in assessing relevance, factuality, and contextual grounding.</p>
    <table>
      <thead>
        <tr><th>Metric</th><th>Evaluation Type</th><th>Focus</th></tr>
      </thead>
      <tbody>
        <tr><td>RAGAS</td><td>LLM + Embeddings</td><td>Factuality, Relevancy, Grounding</td></tr>
    <tr><td>LLM-as-Judge</td><td>LLM</td><td>Holistic Answer Quality</td></tr>
    <tr><td>BERTScore</td><td>Embedding Similarity</td><td>Semantic Similarity</td></tr>
    <tr><td>ROUGE</td><td>Token Overlap</td><td>Surface-level Matching</td></tr>
    <tr><td>BLEU</td><td>Token Overlap</td><td>Precision of N-gram Matches</td></tr>
    <tr><td>METEOR</td><td>Token Overlap + Synonyms</td><td>Recall and Precision with Linguistic Features</td></tr>
    <tr><td>QAEval</td><td>QA-based Evaluation</td><td>Answer Correctness via Question Answering</td></tr>
    <tr><td>ESIM</td><td>Neural Network</td><td>Semantic Textual Similarity</td></tr>
      </tbody>
    </table>
  `
},
{
  title: "Technical Flow Diagram",
  content: `
    <p>This slide will include a visual diagram showing the flow:</p>
    <p> Document ingestion → Embedding via SentenceTransformers → Vector indexing with FAISS → Semantic retrieval → Prompt construction → LLM generation → RAGAS metric evaluation → Result comparison.</p>
  `
},
{
  title: "Setup and Requirements",
  content: `
    <ul>
      <li>Python 3.10+</li>
      <li>Groq API access with LLaMA3 models</li>
      <li>SentenceTransformers, FAISS libraries</li>
      <li>RAGAS library for RAG evaluation metrics (<code>pip install ragas</code>)</li>
      <li>Common imports include: <code>from ragas import FactualCorrectness, AnswerRelevancy, ContextRelevance, ResponseGroundedness</code></li>
    </ul>
  `
},
{
  title: "Use Cases and Applications",
  content: `
    <p>This approach is applicable to building intelligent chatbots, legal question-answering systems, document analysis tools, and any scenario where answers must be grounded in retrieved knowledge.</p>
  `
},


{
  title: "Baseline vs Few-Shots Results",
  content: `
    <p>The following table compares the baseline prompt with the few-shots prompting strategy across RAGAS metrics:</p>
    <table border="1" cellpadding="8" cellspacing="0" style="border-collapse: collapse; width: 100%;">
      <thead>
        <tr style="background-color: #f2f2f2;">
          <th style="font-size: 12px;">Prompt Type</th>
          <th style="font-size: 12px;">FactualCorrectness</th>
          <th style="font-size: 12px;">AnswerRelevancy</th>
          <th style="font-size: 12px;">ContextRelevance</th>
          <th style="font-size: 12px;">ResponseGroundedness</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Baseline</td>
          <td>0.30</td>
          <td>0.53</td>
          <td>1.00</td>
          <td>1.00</td>
        </tr>
        <tr>
          <td>Few-Shots</td>
          <td>0.38</td>
          <td>0.84</td>
          <td>1.00</td>
          <td>1.00</td>
        </tr>
      </tbody>
    </table>

    <p><strong>Summary:</strong> The baseline prompt resulted in partial coverage of GDPR rights, with moderate factual correctness (0.30) and relevancy (0.53), while context relevance and grounding were perfect (1.0). The few-shots prompt improved the answer’s factual correctness (0.38) and relevancy (0.84), maintaining the perfect context relevance and grounding.</p>

    <p><strong>Interpretation:</strong> Few-shots prompting enhanced the model’s ability to produce more relevant and factually accurate answers, while the retrieved context quality remained stable across both prompt types.</p>

   <p><strong>Heatmaps:</strong> Below are the visual comparisons of performance metrics:</p>
<ul>
  <li><em>Heatmap 1:</em> Baseline.</li>
  <li><em>Heatmap 2:Few Shots.</li>
</ul>
<img src="heatmap_baseline.png" alt="Baseline Metrics Heatmap" style="max-width:100%; margin-bottom: 16px;">
<img src="heatmap_fewshots.png" alt="Few-Shots Metrics Heatmap" style="max-width:100%;">

  `
},


{
  title: "Limitations and Future Work",
  content: `
    <p>Current constraints include token-per-minute limits on the Groq API, dependency on high-quality ground truth, and limited batch evaluation capabilities. Future enhancements may involve automated ground truth generation, optimized rate limiting, and expanded metric coverage.</p>
  `
},
{
  title: "Conclusion",
  content: `
    <p>This project demonstrates a practical implementation of RAG with FAISS and LLMs, evaluated through the RAGAS framework. It highlights the impact of prompt engineering on answer quality and provides a solid foundation for further research and real-world applications.</p>
  `
}


   









  ];

  let currentIndex = 0;


function showSlide(index) {
  const slide = slides[index];
  const container = document.getElementById('slide-content');
  container.innerHTML = `<h2>${slide.title}</h2>${slide.content}`;
  currentIndex = index;
  updateButtons();
}

  function updateButtons() {
    document.getElementById('btn-prev').disabled = currentIndex === 0;
    document.getElementById('btn-next').disabled = currentIndex === slides.length - 1;
  }

  document.getElementById('btn-prev').addEventListener('click', () => {
    if (currentIndex > 0) showSlide(currentIndex - 1);
  });

  document.getElementById('btn-next').addEventListener('click', () => {
    if (currentIndex < slides.length - 1) showSlide(currentIndex + 1);
  });

  document.getElementById('btn-home').addEventListener('click', () => {
    window.location.href = 'index.html';
  });

  // Initialize
  showSlide(0);

  if ("serviceWorker" in navigator) {
    navigator.serviceWorker.register("service-worker.js")
      .then(() => console.log("Service Worker registered"))
      .catch(err => console.error("Service Worker registration failed:", err));
  }
</script>

</body>
</html>
